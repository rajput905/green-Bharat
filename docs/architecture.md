# GreenFlow AI â€” System Architecture ğŸ—ï¸

This document describes the technical architecture and design decisions behind GreenFlow AI.

---

## ğŸ“ High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        GreenFlow AI                             â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Data     â”‚â”€â”€â”€â–¶â”‚ Pathway  â”‚â”€â”€â”€â–¶â”‚ FastAPI  â”‚â”€â”€â”€â–¶â”‚Dashboard â”‚  â”‚
â”‚  â”‚ Sources  â”‚    â”‚ Pipeline â”‚    â”‚ Backend  â”‚    â”‚(SSE/JS)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                â”‚               â”‚                        â”‚
â”‚       â”‚          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                  â”‚
â”‚       â”‚          â”‚  SQLite /  â”‚  â”‚ OpenAI   â”‚                  â”‚
â”‚       â”‚          â”‚ PostgreSQL â”‚  â”‚ RAG Engineâ”‚                  â”‚
â”‚       â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Component Architecture

### 1. Data Ingestion Layer (`greenflow/ingestion/`)

Responsible for collecting raw environmental data from multiple sources:

| Source | Format | Description |
|---|---|---|
| JSONL files | `.jsonl` | Drop files into `data/watch/` |
| Kafka | Stream | Real-time broker messages |
| Webhook | HTTP POST | External API push events |
| Simulated Worker | Internal | Background thread generating test data |

```
DataSource â†’ Ingestor â†’ RawEvent â†’ Pipeline
```

The `ingestor.py` normalizes all sources into a unified `RawEvent` schema before passing to the pipeline.

---

### 2. Streaming Pipeline (`greenflow/pipeline/`)

Built on **Pathway** for incremental, real-time computation:

```
RawEvent
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pathway Streaming Graph          â”‚
â”‚                                  â”‚
â”‚  decode_payload()                â”‚
â”‚       â†“                          â”‚
â”‚  classify_source()               â”‚
â”‚       â†“                          â”‚
â”‚  compute_carbon_score()          â”‚
â”‚       â†“                          â”‚
â”‚  enrich_with_metadata()          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
enriched.jsonl  â†’  SQLite DB  â†’  SSE stream
```

**Key design choices:**
- Pathway processes events **incrementally** â€” no full recomputation on new data
- UDFs (User-Defined Functions) are pure Python, easy to extend
- Output written to both file (`enriched.jsonl`) and database for redundancy

---

### 3. Feature Extraction (`greenflow/features/`)

Applies ML-lite scoring to each event:

```python
Features Extracted:
â”œâ”€â”€ carbon_score      # 0.0â€“1.0 relevance to carbon emissions
â”œâ”€â”€ keyword_hits      # Count of environmental keywords matched
â”œâ”€â”€ source_trust      # Reliability score per data source
â””â”€â”€ anomaly_flag      # Boolean: unusual reading detected
```

Uses **keyword-based scoring** + **statistical thresholding** â€” no heavy ML models required, keeping latency low (<5ms per event).

---

### 4. AI / RAG Engine (`greenflow/rag/`)

Powered by **OpenAI GPT-4o** + **ChromaDB**:

```
User Query
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChromaDB Vector â”‚  â† Indexed environmental documents
â”‚ Similarity Searchâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Top-K relevant chunks
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI GPT-4o  â”‚  â† Augmented with retrieved context
â”‚  (RAG Prompt)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Generated answer
         â–¼
     API Response
```

**Endpoints powered by RAG:**
- `POST /api/v1/chatbot/chat` â€” Natural language Q&A
- `POST /api/v1/analytics/recommendation` â€” AI-generated action plan
- `GET /api/v1/analytics/prediction/co2` â€” 30-min COâ‚‚ forecast

---

### 5. REST API Layer (`greenflow/api/`)

Built with **FastAPI** (async, ASGI):

```
Client Request
    â”‚
    â–¼
CORSMiddleware
    â”‚
    â–¼
RequestLoggingMiddleware
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Routers                          â”‚
â”‚  /api/v1/health     â†’ health.py  â”‚
â”‚  /api/v1/analytics  â†’ analytics.pyâ”‚
â”‚  /api/v1/stream     â†’ stream.py  â”‚
â”‚  /api/v1/chatbot    â†’ chatbot.py â”‚
â”‚  /api/v1/simulate   â†’ simulate.pyâ”‚
â”‚  /api/v1/metrics    â†’ metrics.py â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Database Session (AsyncSession)
    â”‚
    â–¼
SQLAlchemy â†’ SQLite (dev) / PostgreSQL (prod)
```

**Key patterns:**
- All routes are **async** for maximum concurrency
- Database sessions injected via **FastAPI dependency injection**
- Responses validated with **Pydantic** schemas
- OpenAPI docs auto-generated at `/docs`

---

### 6. Real-Time Streaming (`/api/v1/stream/events`)

Two protocols supported:

#### Server-Sent Events (SSE)
```
Browser â”€â”€â”€â”€ GET /api/v1/stream/events â”€â”€â”€â”€â–¶ Server
       â—€â”€â”€â”€ text/event-stream â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       â—€â”€â”€â”€ data: {"aqi": 76, "temp": 29} â”€
       â—€â”€â”€â”€ data: {"aqi": 78, "temp": 29} â”€
       â—€â”€â”€â”€ ... (polling DB every 2s)      â”€
```

#### WebSocket
```
Browser â—€â”€â”€â”€â”€ WS /api/v1/stream/ws â”€â”€â”€â”€â”€â”€â”€â–¶ Server
        â—€â”€â”€â”€ Bi-directional messages â”€â”€â”€â”€â”€â”€â–¶
```

The SSE generator polls `analytics_records` table every 2 seconds and pushes new records to all connected clients.

---

### 7. Database Layer (`greenflow/database/`)

Using **SQLAlchemy async** with two backends:

| Environment | Database | URL |
|---|---|---|
| Development | SQLite | `data/greenflow_dev.db` |
| Production | PostgreSQL | `postgresql+asyncpg://...` |

**Schema:**

```sql
-- analytics_records: Core telemetry table
CREATE TABLE analytics_records (
    id          INTEGER PRIMARY KEY,
    timestamp   FLOAT NOT NULL,
    city        VARCHAR(50),
    temp        FLOAT,
    humidity    FLOAT,
    aqi         INTEGER,
    avg_aqi_10m FLOAT,
    risk_score  FLOAT,
    safety_level VARCHAR(20),
    created_at  DATETIME DEFAULT NOW()
);

-- green_events: Raw ingested events
CREATE TABLE green_events (
    id          INTEGER PRIMARY KEY,
    event_id    VARCHAR(64) UNIQUE,
    source      VARCHAR(128),
    source_type VARCHAR(64),
    raw_text    TEXT,
    carbon_score FLOAT,
    created_at  DATETIME DEFAULT NOW()
);

-- query_logs: RAG audit trail
CREATE TABLE query_logs (
    id          INTEGER PRIMARY KEY,
    query_text  TEXT,
    answer      TEXT,
    latency_ms  FLOAT,
    created_at  DATETIME DEFAULT NOW()
);
```

---

### 8. Frontend (`greenflow/frontend/`)

Pure **Vanilla JS** â€” no build step, no framework:

```
index.html  â† HTML structure, semantic & accessible
style.css   â† CSS custom properties, glassmorphism UI
script.js   â† API polling + SSE connection + DOM updates
```

**Data flow in browser:**
```
DOMContentLoaded
    â”‚
    â”œâ”€â”€ connectSSE()        â†’ EventSource â†’ updates KPIs in real-time
    â”œâ”€â”€ pollAll() every 15s â†’ fetchPrediction(), fetchRisk(), fetchRecommendation()
    â”œâ”€â”€ updateSimulator()   â†’ POST /simulate â†’ displays what-if results
    â””â”€â”€ fetchExecutiveSummary() every 60s â†’ RAG chatbot â†’ typewriter display
```

---

## ğŸ”’ Security Architecture

| Concern | Approach |
|---|---|
| API Keys | Stored in `.env`, never committed to git |
| CORS | Restricted to configured origins |
| Input Validation | Pydantic schemas on all endpoints |
| SQL Injection | SQLAlchemy ORM (parametrized queries) |
| Rate Limiting | Planned via `slowapi` (future) |

---

## ğŸš€ Scalability Design

### Horizontal Scaling
```bash
# Multiple Uvicorn workers
uvicorn greenflow.main:app --workers 4 --host 0.0.0.0 --port 8000
```

### Vertical Scaling Path
```
SQLite (dev, 1 user)
    â†“
PostgreSQL (production, 100s of users)
    â†“
PostgreSQL + Redis cache (1000s of users)
    â†“
Distributed Pathway + Kafka (enterprise)
```

### Docker Architecture
```
docker-compose.yml
â”œâ”€â”€ db          â†’ PostgreSQL 15
â”œâ”€â”€ engine      â†’ Pathway pipeline worker
â”œâ”€â”€ api         â†’ FastAPI (port 8000)
â””â”€â”€ ui          â†’ Streamlit dashboard (port 8501)
```

---

## ğŸ“Š Data Flow Diagram

```
[IoT Sensor / File / API]
         â”‚
         â–¼
   [Ingestor.py]
   Normalize â†’ RawEvent
         â”‚
         â–¼
 [Pathway Pipeline]
 Score â†’ Enrich â†’ Store
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
[SQLite]  [JSONL file]
    â”‚         â”‚
    â–¼         â–¼
[FastAPI] [SSE Tail]
    â”‚         â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â–¼
  [Browser Dashboard]
  KPIs + Charts + Alerts
```

---

## ğŸ§ª Testing Strategy

| Type | Tool | Coverage |
|---|---|---|
| Unit Tests | `pytest` | Core business logic |
| API Tests | `pytest` + `httpx` | All endpoints |
| Integration Tests | `pytest` + real DB | Full pipeline |
| Load Tests | `locust` (planned) | SSE under load |

---

*Last updated: February 2025 Â· GreenFlow AI Team*
